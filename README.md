# ğŸµ Filharmonia AI

AI-powered concert audio analysis system using **PyTorch Audio Spectrogram Transformer (AST)** for automatic classification and segmentation of philharmonic concert recordings.

## ğŸ“‹ Features

- **ğŸ¼ Audio Classification**: Automatically classifies audio into 5 categories:
  - ğŸµ MUSIC - orchestral music
  - ğŸ‘ APPLAUSE - audience applause
  - ğŸ—£ï¸ SPEECH - announcements, speeches
  - ğŸ‘¥ PUBLIC - audience noise, intermission
  - ğŸ» TUNING - instrument tuning

- **ğŸ¨ Visual Waveform Editor**: DAW-style interface for reviewing and correcting predictions
- **ğŸ¤– Self-Improving ML Loop**: Export corrected segments â†’ retrain model â†’ improved accuracy
- **ğŸ“Š Model Management**: Train, compare, and switch between models with measured accuracy
- **ğŸ“ˆ Uncertainty Review**: Filter low-confidence predictions for manual review
- **âš¡ GPU Accelerated**: CUDA support for fast training and inference

## ğŸ—ï¸ Architecture

```
filharmonia-ai/
â”œâ”€â”€ backend/              # FastAPI + PyTorch backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/v1/      # REST API endpoints
â”‚   â”‚   â”œâ”€â”€ services/    # Core business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ ast_training.py    # Model training service
â”‚   â”‚   â”‚   â”œâ”€â”€ ast_inference.py   # Model inference service
â”‚   â”‚   â”‚   â””â”€â”€ analyze.py         # Audio analysis pipeline
â”‚   â”‚   â””â”€â”€ config.py    # Settings and paths
â”‚   â”œâ”€â”€ pytorch_dataset.py         # Custom PyTorch dataset
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/            # React + TypeScript + Vite
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/  # UI components
â”‚   â”‚   â”œâ”€â”€ pages/       # Page views
â”‚   â”‚   â””â”€â”€ api/         # API client
â”‚   â””â”€â”€ package.json
â”‚
â””â”€â”€ .claude/             # Project documentation
    â”œâ”€â”€ PROJECT_OVERVIEW.md
    â”œâ”€â”€ ARCHITECTURE.md
    â””â”€â”€ QUICK_START.md
```

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.11+**
- **Node.js 18+** (with pnpm)
- **NVIDIA GPU** (optional but recommended for training)
- **CUDA 12.x** (if using GPU)

### Backend Setup

```bash
cd backend

# Create virtual environment
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt

# Run backend
python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

Backend will be available at: `http://localhost:8000`

### Frontend Setup

```bash
cd frontend

# Install dependencies
pnpm install

# Run dev server
pnpm dev
```

Frontend will be available at: `http://localhost:5173`

## ğŸ“Š Model Training

The system uses **Audio Spectrogram Transformer (AST)** from MIT:
- Pre-trained on AudioSet-10M
- Fine-tuned on concert recordings
- ~86M parameters
- Training time: ~4h on RTX 3080 Ti

**Training new model:**
1. Prepare training data in `TRAINING DATA/DATA/` folder (5 class subfolders)
2. Open web UI â†’ "Training" tab
3. Click "Start Training"
4. Monitor progress in real-time
5. Click "ğŸ“Š Measure" to evaluate accuracy
6. Click "Activate" to deploy new model

## ğŸ¯ Performance

**Current best model (ast_20251009_222204.pth):**
- Test Accuracy: **97.75%**
- Per-class accuracy:
  - APPLAUSE: 100%
  - MUSIC: 100%
  - PUBLIC: 96.2%
  - SPEECH: 100%
  - TUNING: 85.7%

## ğŸ”§ Configuration

Edit `backend/app/config.py` to configure:
- Training data paths
- Model save location
- Sample rate & duration
- GPU/CPU device selection

## ğŸ“ Workflow

1. **Sort Recordings**: Organize MP3 files by date using ID3 tags
2. **Analyze**: Process concerts through AST model (~5 min per 1h concert)
3. **Review**: Visual waveform editor for corrections
4. **Export**: Generate tracklists for clients
5. **Train**: Export corrected segments â†’ retrain model â†’ improved accuracy

## ğŸ› ï¸ Tech Stack

**Backend:**
- FastAPI (REST API)
- PyTorch + torchaudio (ML)
- HuggingFace Transformers (AST model)
- scikit-learn (dataset splitting)

**Frontend:**
- React 18 + TypeScript
- Vite (build tool)
- TanStack Query (data fetching)
- Recharts (visualizations)
- Tailwind CSS (styling)

## ğŸ“š Documentation

Detailed documentation available in `.claude/` folder:
- `PROJECT_OVERVIEW.md` - Project goals and architecture
- `ARCHITECTURE.md` - Technical architecture details
- `QUICK_START.md` - Development setup guide
- `CLAUDE.md` - Claude Code assistant guide

## ğŸ¤ Contributing

This is a private project for Filharmonia workflow automation. For questions or collaboration, contact the project maintainer.

## ğŸ“„ License

Private project - all rights reserved.

## ğŸ‰ Achievements

- âœ… MVP completed (Oct 2025)
- âœ… Migrated from Keras CNN to PyTorch AST
- âœ… Achieved 97.75% test accuracy
- âœ… Reduced monthly processing time from 4-6h to ~30 min
- âœ… Implemented self-improving ML loop

---

**Last Updated:** October 2025
**Status:** ğŸš€ Production Ready (MVP)
